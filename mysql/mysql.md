





### 基础

#### MyISAM和InnoDB的区别

1. myisam锁粒度到表级 innodb锁粒度到行级
2. Myisam不支持事务 innodb支持事务
3. myisam不支持外键 innodb支持外键
4. 索引类型不同

#### limit 查询优化

覆盖索引找到ID 然后再limit

#### 数据库三范式举例+BCNF范式

第一范式(1NF)

> 指的是数据库表的中的每一列都是不可分割的基本数据项,同一列中不能有多个值。第一范式要求属性值是不可再分割成的更小的部分。第一范式简而言之就是强调的是列的原子性，即列不能够再分成其他几列。例如有一个列是电话号码一个人可能有一个办公电话一个移动电话。第一范式就需要拆开成两个属性

第二范式（2NF）

> 第二范式首先是第一范式，同时还需要包含两个方面的内容，一是表必须要有一个主键；二是没有包含主键中的列必须完全依赖主键，而不能只是依赖于主键的一部分。
>
> 例如在一个订单中可以订购多种产品，所以单单一个 OrderID 是不足以成为主键的，主键应该是（OrderID，ProductID）。显而易见 Discount（折扣），Quantity（数量）完全依赖（取决）于主键（OderID，ProductID），而 UnitPrice，ProductName 只依赖于 ProductID。所以 OrderDetail 表不符合 2NF。不符合2NF 的设计容易产生冗余数据。 可以把【OrderDetail】表拆分为【OrderDetail】（OrderID，ProductID，Discount，Quantity）和【Product】（ProductID，UnitPrice，ProductName）来消除原订单表中UnitPrice，ProductName多次重复的情况。

第三范式（3NF）

> 首先是第二范式，例外非主键列必须依赖于主键，不能存在传递。也就是说不能存在非主键列A依赖于非主键列B，然后B依赖于主键列考虑一个订单表【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID）。 其中 OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity 等非主键列都完全依赖于主键（OrderID），所以符合 2NF。不过问题是 CustomerName，CustomerAddr，CustomerCity 直接依赖的是 CustomerID（非主键列），而不是直接依赖于主键，它是通过传递才依赖于主键，所以不符合 3NF。通过拆分【Order】为【Order】（OrderID，OrderDate，CustomerID）和【Customer】（CustomerID，CustomerName，CustomerAddr，CustomerCity）从而达到 3NF。二范式（2NF）和第三范式（3NF）的概念很容易混淆，区分它们的关键点在于，2NF：非主键列是否完全依赖于主键，还是依赖于主键的一部分；3NF：非主键列是直接依赖于主键，还是直接依赖于非主键

#### 数据库的事务隔离级别? 脏读、不可重复读、幻读？



#### sql语句的执行过程，写完一条sql语句之后过程是怎样的？



#### MySQL为什么用B+树不用红黑树

因为要提搞效率 一次磁盘IO读出一整个簇 这个簇中要写尽可能多出现读用的数据

红黑树深度太深 要IO读写次数过多

- 哈希虽然能够提供 `O(1)` 的单数据行操作性能，但是对于范围查询和排序却无法很好地支持，最终导致全表扫描；
- B 树和红黑树能够在非叶节点中存储数据，导致数的高度变大，需要更多的iO次数
  - 而 B+ 树的所有叶节点可以通过指针相互连接，能够减少顺序遍历时产生的额外随机 I/O，更多的使用顺序IO；

https://blog.csdn.net/zl1zl2zl3/article/details/107063453?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-2&spm=1001.2101.3001.4242

#### 一条mysql查询经历了什么

1. 建立连接 权限鉴定 保持连接 长连接 短连接
2. 查询缓存 key~value
3. 分析器  **“词法分析”** 与 **“语法分析”**
4. 优化器 
5. 执行器

#### Mysql为什么不用uuid作为表的主键

1. UUID生成速率低下

2. uuid占用的空间较大

3. UUID主键在innodb中会引发性能问题

   innodb中的主键索引也是聚集索引，如果插入的数据是顺序的，那么b+树的叶子基本都是满的，缓存也可以很好的发挥作用。如果插入的数据是完全无序的，那么叶子节点会频繁分裂，缓存也基本无效了。这会减少tps

#### MyISAM和InnoDB索引的区别？

1. MyISAM是**非聚簇索引**。

   索引文件和数据文件是分离的，索引文件仅保存记录所在页的指针（物理位置），通过这些地址来读取页，进而读取被索引的行。

   1. 其主键索引与普通索引没有本质差异

2. nnoDB的**主键索引与**行记录是存储在一起的，故叫做**聚集索引** 

   1. InnoDB的**普通索引**可以有多个，它与聚集索引是不同的：
      - 普通索引的叶子节点，存储主键（也不是指针）

#### 什么是事务？事务隔离级别和MVCC？



#### MySQL 死锁发生的原因和解决

https://www.cnblogs.com/LBSer/p/5183300.html

innodb死锁检测

1. 两个事务相互等待时，当一个等待时间超过设置的某一阀值时，对其中一个事务进行回滚，另一个事务就能继续执行。这种方法简单有效，在innodb中，参数innodb_lock_wait_timeout用来设置超时时间。

2. 环路就是死锁！这就是wait-for graph算法。
   ![img](http://img3.tbcdn.cn/L1/461/1/2efd7fac0ff4acd2d2c17f0496926181bfa15f9b.png)                                              图3 wait for graph

      innodb将各个事务看为一个个节点，资源就是各个事务占用的锁，当事务1需要等待事务2的锁时，就生成一条有向边从1指向2，最后行成一个有向图。

https://blog.csdn.net/riemann_/article/details/91349331

\1. 事务之间对资源访问顺序的交替

出现原因： 
一个用户A 访问表A（锁住了表A），然后又访问表B；另一个用户B 访问表B（锁住了表B），然后企图访问表A；这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了。

解决方法： 
这种死锁比较常见，是由于程序的BUG产生的，除了调整的程序的逻辑没有其它的办法。仔细分析程序的逻辑，对于数据库的多表操作时，尽量按照相同的顺序进行处理，尽量避免同时锁定两个资源，如操作A和B两张表时，总是按先A后B的顺序处理， 必须同时锁定两个资源时，要保证在任何时刻都应该按照相同的顺序来锁定资源

\2. 并发修改同一记录

出现原因：主要是由于没有一次性申请够权限的锁导致的。参考：[记录一次死锁排查过程](http://www.kissyu.org/2017/02/19/记录一次Mysql死锁排查过程/)

用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户B里的独占锁由于A有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升的独占锁也就不可能释放共享锁，于是出现了死锁。这种死锁比较隐蔽，但在稍大点的项目中经常发生。 

解决方法：

a. 乐观锁，实现写-写并发

b. 悲观锁：使用悲观锁进行控制。悲观锁大多数情况下依靠数据库的锁机制实现，如Oracle的Select … for update语句，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。

\3. 索引不当导致的死锁

出现原因： 
如果在事务中执行了一条不满足条件的语句，执行全表扫描，把行级锁上升为表级锁，多个这样的事务执行后，就很容易产生死锁和阻塞。类似的情况还有当表中的数据量非常庞大而索引建的过少或不合适的时候，使得经常发生全表扫描，最终应用系统会越来越慢，最终发生阻塞或死锁。

另外一种情况是由于二级索引的存在，上锁的顺序不同导致的，这部分在讨论索引时会提到。参考：https://www.cnblogs.com/LBSer/p/5183300.html

解决方法：

SQL语句中不要使用太复杂的关联多表的查询；使用“执行计划”对SQL语句进行分析，对于有全表扫描的SQL语句，建立相应的索引进行优化。

 

那么，如何尽可能的避免死锁呢？

1）以固定的顺序访问表和行。即按顺序申请锁，这样就不会造成互相等待的场面。

2）大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。

3）在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。

4）降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。

5）为表添加合理的索引。如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。

#### MySQL分库分表的方案？

（我介绍了我们使用的三种方式，hash法、range法以及当前正在使用的hash+range法）

横向 和 纵向

横向可以把主键hash mod 实现分表查询

纵向可以把用的不是很多的属性单独分一个表  把大数据字段单独分一个表



#### 行级锁和表级锁

https://www.cnblogs.com/rjzheng/p/9950951.html

当查询的索引含有唯一属性时，将next-key lock降级为record key

## 索引

#### Count(*) 和 count(主键) 和 count(1)

在任何版本，count(*) = count(主键) ≈ count(1)性能均为最佳

mysql5.5-5.6版本：count(最短二级索引字段) = count(*)，性能取决于索引长短，越短越快

mysql5.7及以上：count(所有非空二级索引) = count(*)，只要将二级索引约束非空，则无需再关心该索引长短，性能均最佳

#### Mysql事务ACID实现原理

https://www.cnblogs.com/rjzheng/p/10841031.html

#### MySQL索引有哪些，基于数据结构的分类一下？基于hash和B+树的有什么区别、复杂度？什么时候要建立索引？



#### 索引最左原则，模糊查询一定索引失效?



#### 我现在要看一下索引有没有起作用，请问，我该怎么操作



#### B+树，为什么用B+树，B+树查找历程？索引详细？



#### Where a=xxx and b=xxx and c=xxx，abc都有索引，会如何进行？

a,b,c走索引

a 走索引

a,b走索引 a.b索引

a,c走索引 走a的索引



#### explain用法

select_type: SELECT 查询的类型 说明我们用没用子查询 union之类的

table: 查询的是哪个表

type: 

```
system: 表中只有一条数据. 这个类型是特殊的 const 类型.

const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可.

ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询.

range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN() 操作中.
当 type 是 range 时, 那么 EXPLAIN 输出的 ref 字段为 NULL, 并且 key_len 字段是此次查询中使用到的索引的最长的那个.

index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.
index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index.

ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免.


通常来说, 不同的 type 类型的性能关系如下:
ALL < index < range ~ index_merge < ref < eq_ref < const < system
ALL 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.
而 index 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.
后面的几种类型都是利用了索引来查询数据, 因此可以过滤部分或大部分数据, 因此查询效率就比较高了

```



possible_keys: 此次查询中可能选用的索引

key: 此次查询中确切使用到的索引.

ref: 哪个字段或常数与 key 一起被使用



#### buffer pool

https://blog.csdn.net/howinfun/article/details/104380418

1、MySQL 启动时会根据分配指定大小内存给 Buffer Pool，并且会创建一个个描述数据块和缓存页。

2、SQL 进来时，首先会根据数据的表空间和数据页编号查询 数据页缓存哈希表 中是否有对应的缓存页。

3、如果有对应的缓存页，则直接在 Buffer Pool中执行。

4、如果没有，则检查 free 链表看看有没有空闲的缓存页。

5、如果有空闲的缓存页，则从磁盘中加载对应的数据页，然后将描述数据块从 free 链表中移除，并且加入到 lru 链表的冷数据区域的链表头部。后面如果被修改了，还需要加入到 flush 链表中。

6、如果没有空闲的缓存页，则将 lru 链表的冷数据区域的链表尾部的缓存页刷回磁盘，然后清空，接着将数据页的数据加载到缓存页中，并且描述数据块会加入到 lru 链表的冷数据区域的链表头部。后面如果被修改了，还需要加入到 flush 链表中。

7、5或者6后，就接着在 Buffer Pool 中执行增删改查。

注意：5和6中，缓存页加入到冷数据区域的链表头部后，如果在 1s 后被访问，则将入到热数据区域的链表头部。

8、最后，就是描述数据块随着 SQL 语句的执行不断地在 free 链表、flush 链表和 lru 链表中移动了。

## mysql调优

首先看内存情况 buffer pool instance的数量和总的大小是不是正常的

然后用explain 看index列看有没有命中索引

没有命中的话 是不是以下问题

1. 使用索引最左匹配原则，选择性大的列放前面。
2. `like`左边不要使用`%`，会导致索引失效。
3. where查询时，索引列不要做运算或函数的参数。
4. 尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描。
5. 避免在WHERE子句中使用 != 或 <>操作符，否则将引擎放弃使用索引而进行全表扫描。
6. 使用 JOIN 级联查询时，应该保证两表中 JOIN 的字段已建立过索引且类型相同。
7. 尽可能的使用 NOT NULL：NULL会占用额外的空间来记录其值是否为空。
8. 拆分大的 DELETE 或 INSERT 语句，避免长时间锁表。
9. 不用外键，不用UNIQUE，由程序保证约束。
10. 使用OR时，前后条件都必须是索引，否则索引失效。

最好查出来的东西不要太大 用联合索引 尽量避免回表 用顺序IO而不是随机IO

#### 调优方式

1. 缓存失效
2. 慢查询日志
3. explain看 type key extre ref 是不是因为**隐式类型转换**或者**隐式字符编码转换**导致使用了转换函数没用上索引
4. 覆盖索引避免回表
5. 联合索引 最左前缀+避免索引失效
6. 索引下推 在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。



#### flush

redo log大家都知道，也就是我们对数据库操作的日志，他是在内存中的，每次操作一旦写了redo log就会立马返回结果，但是这个redo log总会找个时间去更新到磁盘，这个操作就是flush。

在更新之前，当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。

内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页“。

**那什么时候会flush呢？**

1. InnoDB的redo log写满了，这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。
2. 系统内存不足，当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。

> 你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？

这里其实是从性能考虑的，如果刷脏页一定会写盘，就保证了每个数据页有两种状态：

- 一种是内存里存在，内存里就肯定是正确的结果，直接返回；
- 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。 这样的效率最高。

1. MySQL认为系统“空闲”的时候，只要有机会就刷一点“脏页”。
2. MySQL正常关闭，这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

![img](https://pic4.zhimg.com/80/v2-fffc657edcda47b381a8de4170d76848_720w.jpg)

**那我们怎么做才能把握flush的时机呢？**

Innodb刷脏页控制策略，我们每个电脑主机的io能力是不一样的，你要正确地告诉InnoDB所在主机的IO能力，这样InnoDB才能知道需要全力刷脏页的时候，可以刷多快。

这就要用到innodb_io_capacity这个参数了，它会告诉InnoDB你的磁盘能力，这个值建议设置成磁盘的IOPS，磁盘的IOPS可以通过fio这个工具来测试。

正确地设置innodb_io_capacity参数，可以有效的解决这个问题。

这中间有个有意思的点，刷脏页的时候，旁边如果也是脏页，会一起刷掉的，并且如果周围还有脏页，这个连带责任制会一直蔓延，这种情况其实在机械硬盘时代比较好，一次IO就解决了所有问题，

![img](https://pic3.zhimg.com/80/v2-9bac2ff954cee00a3d839ca5338799bb_720w.jpg)

但是现在都是固态硬盘了，innodb_flush_neighbors=0这个参数可以不产生连带制，在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。

#### 慢查询

让MySQL记录下查询超过指定时间的语句，我们将超过指定时间的SQL语句查询称为“慢查询”

慢查询主要体现在慢上，通常意义上来讲，只要返回时间大于 >1 sec上的查询都可以称为慢查询。慢查询会导致CPU，内存消耗过高。数据库服务器压力陡然过大，那么大部分情况来讲，肯定是由某些慢查询导致的。

```cpp
long_query_time = 10
log-slow-queries = /var/lib/mysql/mysql-slow.log
```

#### 读写分离

MySQL读写分离能提高系统性能的原因在于：

- 物理服务器增加，机器处理能力提升。拿硬件换性能。
- 主从只负责各自的读和写，极大程度缓解X锁和S锁争用。
- slave可以配置myiasm引擎，提升查询性能以及节约系统开销。
- master直接写是并发的，slave通过主库发送来的binlog恢复数据是异步。
- slave可以单独设置一些参数来提升其读的性能。
- 增加冗余，提高可用性。



## mysql逻辑分级

表-> 段（segment）-> 区（extend）->页（page）->槽（没有正式数据结构，维护了几个字段类似于数组的头结点）->数据记录

一个槽内有4~8个数据记录

一个页内有多少条数据主要取决于一条数据大小，数据页默认为16K

一个区默认有64个页

一个段（是一个逻辑概念）是某些零散页以及完整取的集合，存储叶子节点的区集合和非叶子节点的区集合

表空间由若干个区构成，每个区都对应一个Entry结构，直属于表空间的区的Entry结构可以构成FREE，FREE_FRAG，FULL_FRAG这三个链表。

直属于段的区的Entry结构，可以构成FREE（全是空闲页）、NOT_FULL（有空闲页）、FULL（无空闲页）三个链表。

### 为什么要引入槽

维护一个槽的概念，存在一个槽头数据的偏移量数组，通过对槽头数据的二分法查找目标主键所在的槽

### 为什么要引入页

树形结构 提高查找效率

### 为什么要引入区

如果逻辑上相邻双向链表链接的两个页物理位置总是不连续的，查询时会导致随机IO，影响磁盘性能。所以尽量让页面链表中相邻页的物理位置也相邻，使用顺序IO。区内64个页在物理上是连续的，B+数的叶子节点和非叶子节点都是有自己独有的区。

区有四种类型：

| 状态名    | 含义                     |
| --------- | ------------------------ |
| FREE      | 空闲的区                 |
| FREE_FRAG | 有剩余空闲页面的碎片区   |
| FULL_FRAG | 没有剩余空闲页面的碎片区 |
| FSEG      | 附属于某个段的区         |




### 为什么要引入段

段的存储空间分配策略：

* 刚开始向表中插入数据是，从某个碎片区（fragment 一个碎片区内不是所有的页都是属于同一个段 直属于表空间）内以单个页面为单位分配给段
* 当某个段已经占用了32个碎片页面之后，就会以完整的区为单位来分配

每个索引对应两个段，分别存储叶子节点的区集合和非叶子节点区的集合

# 日志

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/91f5947bf7a941aebeebe219bc1bb43e~tplv-k3u1fbpfcp-zoom-1.image)

https://bytetech.info/articles/7317336837398200370?from=message_bot&sender_type=101&message_id=7345314080619577354#heading3

https://relph1119.github.io/mysql-learning-notes/#/mysql/01-%E8%A3%85%E4%BD%9C%E8%87%AA%E5%B7%B1%E6%98%AF%E4%B8%AA%E5%B0%8F%E7%99%BD-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86MySQL



### Buffer pool

是Mysql的一块内存空间，缓存硬盘数据，将硬盘IO简化为内存操作

### Binlog

是MysqlServer的逻辑日志，记录的是对哪一个表的哪一行做了什么修改，是追加写所以效率高。

和redo log日志类似，binlog也有着自己的刷盘策略，通过sync_binlog参数控制：

- sync_binlog = 0 ：每次提交事务前将binlog写入os cache，由操作系统控制什么时候刷到磁盘
- sync_binlog =1 ：采用同步写磁盘的方式来写binlog，不使用os cache来写binlog
- sync_binlog = N ：当每进行n次事务提交之后，调用一次fsync将os cache中的binlog强制刷到磁盘

binlog严格来说可以分为两种格式：**基于语句的日志(statement-based logging)和基于行的日志(row-based logging)。**



### Redo Log

 InnoDB引擎特有，主要作用是恢复崩溃。redo log是物理日志，记录的是对哪个数据页中的哪个记录做了什么修改

redolog可以视作一个环形文件区，其中checkpoint_lsn表示已经持久化到磁盘的事务的lsn(log sequeue number)，write_lsn表示下一个执行的事务的写入位置，从checkpoint_lsn到write_lsn之间的区域表示没有持久化到磁盘中事务。

有三种刷盘策略，可以在配置文件中切换。区别是刷盘的实际，推荐的是第三种，用OS cache 即使mysql宕机，os也会刷盘，但是操作系统宕机了就没办法了



1. innodb_flush_log_at_trx_commit = 1：实时写，实时刷

> 这种策略会在每次事务提交之前，每次都会将数据从redo log刷到磁盘中去，理论上只要磁盘不出问题，数据就不会丢失。
>
> 总结来说，这种策略效率最低，但是丢数据风险也最低。

1. innodb_flush_log_at_trx_commit = 0：延迟写，延迟刷

> 这种策略在事务提交时，只会把数据写到redo log buffer中，然后让后台线程定时去将redo log buffer里面的数据刷到磁盘。
>
> 这种策略是最高效的，但是我们都知道，定时任务是有间隙的，但是如果事务提交后，后台线程没来得及将redo log刷到磁盘，这个时候不管是MySQL进程挂了还是操作系统挂了，这一部分数据都会丢失。
>
> 总结来说这种策略效率最高，丢数据的风险也最高。

1. innodb_flush_log_at_trx_commit = 2：实时写，延迟刷

> 这种策略在事务提交之前会把redo log写到**os cache**中，但并不会实时地将redo log刷到磁盘，而是会每秒执行一次刷新磁盘操作。
>
> 这种情况下如果MySQL进程挂了，操作系统没挂的话，操作系统还是会将os cache刷到磁盘，数据不会丢失，如下图：

### Undo log

回滚日志，



需要注意的是，undo log默认存在全局表空间里面，你可以简单的理解成undo log也是记录在一个MySQL的表里面，插入一条undo log和插入一条普通数据是类似。也就是说，写undo log的过程中同样也是要写入redo log的。



### 为什么需要用redolog来做crash-safe？binlog不是包含了所有的改动吗？

- 设计目的上：binlog在设计之初是为了归档而不是崩溃恢复，其想要解决的问题和崩溃恢复本身也不相同。“**崩溃恢复就是为了将这部分更新在buffer pool、已经返回commit成功、未持久化到磁盘的事务重新持久化到磁盘**。”而binlog根本不知道哪些SQL符合这个条件，用binlog进行的恢复更多是异常恢复，这两种恢复存在区别。

> 崩溃恢复可以类比成电脑突然关机重启了，怎么保证我在重启前做的操作尽可能少地丢失；
>
> 异常恢复可以类比成我不小心一脚把电脑踢坏了，怎么尽可能地将电脑恢复成正常状态。

- 可行性上：理论上**也许**可行，但生产环境不可行。
  - 理论上：只需要在崩溃后将binlog进行重放看起来就可以将数据库带到崩溃前的状态。
  - 生产环境中：从哪里开始重放？并且binlog并没有保证其中的语句是可重入的，如果其中有类似于update value=value+1直接重放可能会导致问题。
  - **核心的点在于：binlog不知道哪些改动已经持久化到磁盘了，也即其设计之初就不是为了做崩溃恢复这件事。**
- 抽象上：崩溃恢复是InnoDB在引入buffer pool后带来的问题，InnoDB选择自身实现两种日志来满足事务的ACID属性；如果强行用双指针+binlog来做，相当于让引擎层的功能耦合到了Server层，设计上来说不好。

### 如何保证主库和从库在各种情况下都能达到最终一致的状态

这里说的一致性主要是如何保证主库和从库在各种情况下都能达到最终一致的状态，想要实现这个目标需要做到两件事：1. 主库要保证自身的改动都能同步到从库 2. 主库要保证在发生crash的情况下自身和从库的状态一致。而落到具体的技术实现上就是解决两个问题：**1. 主库如何保证binlog和自身事务的提交一致 2.** **主库如何保证binlog和redolog的信息一致。**

#### binlog与事务的一致性

**#Why？**

MySQL使用binlog进行主从复制，从库的变更全部依赖于主库的binlog日志。如果主库事务提交并持久化成功，而binlog持久化失败，主库在发生异常崩溃的时候无法将这个事务产生的影响同步给从库，主从产生了不一致；反过来，如果binlog持久化成功而事务产生的结果持久化失败，在崩溃重启后主库能够通过结合binlog中的信息将事务重新执行，此时主从不会产生不一致。**因此只有在事务对应的binlog持久化成功的情况下能够将事务进行commit。**

**#How？**

每条SQL执行之前会先写入binlog cache，在执行commit操作时会根据[sync_binlog](https://dev.mysql.com/doc/refman/5.7/en/replication-options-binary-log.html#sysvar_sync_binlog)参数的配置决定是否要对binlog进行刷盘持久化。默认情况下sync_binlog=1，代表着每次commit前都会进行刷盘操作；还能够将其设置为N，代表每N次commit完成一次刷盘。

刷盘时会将binlog cache中的数据都写入binlog文件，完成binlog的持久化。在sync_binlog=1的前提下：**binlog的完成持久化=事务提交。**

#### binlog与redolog的一致性

**#Why？**

从redolog/undolog简介中可以看到InnoDB引擎会使用redolog进行事务的恢复，因为在主从架构下写操作发生在主，异常的恢复也是在主库执行。

如果redolog写入成功、binlog写入失败，在崩溃重启后，主库能够通过redolog将事务重做，因为binlog中没有对应的操作记录，从库将无法将这次事务产生的影响同步到自身，产生了主从不一致的问题；反过来redolog写入失败、binlog写入成功，在崩溃重启后，从库能够从binlog将事务的改动同步到自身，而主库因为使用redolog、undolog来进行事务的重做与回滚，主库无法事务的变更应用到自身，因此主从也会有不一致的问题。

**#How？** 

暂时无法在飞书文档外展示此内容

**MySQL通过****两阶段提交****来保证二者的一致性。**具体流程如左图。

事务提交时：

1. 首先进入prepare阶段，这阶段会将状态为prepare的redolog进行持久化
2. commit阶段首先会将binlog持久化
3. 随后将redolog的状态设置为commit
4. 返回事务commit成功

在这里不变的一点是：**binlog的完成持久化=事务提交。**

在崩溃重启时会遍历redolog，对于状态为commit且对应事务没有持久化的事务，直接进行重做；对于状态为prepare的redolog会通过事务id查询binlog，看在binlog中该事务是否存在(事务的提交在binlog中的表现是存在一个xid)，存在则进行事务重做；否则将事务回滚。

![image-20240322114709036](/Users/bytedance/Library/Application Support/typora-user-images/image-20240322114709036.png)

时刻1的崩溃对应->redolog=prepare，binlog不存在

时刻2的崩溃对应->redolog=prepare，binlog存在

综上，通过两阶段提交能够保证在任何时间崩溃，redolog和binlog的状态都能使得主从的状态是一致的。